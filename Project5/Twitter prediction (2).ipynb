{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity Prediction\n",
    "## Problem 1.1\n",
    "As a preliminary step, we calculated the following statistics to get a holistic overview of the twitter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import os\n",
    "import tqdm #python for loop progress bar\n",
    "\n",
    "import datetime, time\n",
    "import pytz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these values were found via wc -l in CLI\n",
    "hashtag_dict = {\n",
    "    'gohawks':188136,\n",
    "    'gopatriots':26232,\n",
    "    'nfl':259024,\n",
    "    'patriots':489713,\n",
    "    'sb49':826951,\n",
    "    'superbowl':1348767\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_matrix(raw_df, index='date', mat_type='full'):\n",
    "    \"\"\"\n",
    "    Iterates through the rows of the created dataframe and performs summing, maxes, and \n",
    "    creates time series\n",
    "    \"\"\"\n",
    "    raw_df = raw_df.set_index(index)\n",
    "    time_series = raw_df.groupby(pd.TimeGrouper(freq='60Min'))\n",
    "    \n",
    "    X = np.zeros((len(time_series), 8))\n",
    "    y = np.zeros((len(time_series), 1))\n",
    "    for i, (time_interval, g) in enumerate(time_series):\n",
    "        \"\"\"\n",
    "        #get the date for sorting\n",
    "        date = datetime.fromtimestamp(tweet_data['firstpost_date'])\n",
    "        df.set_value(i, 'date', date)\n",
    "        df.set_value(i, 'total_tweets', 1)\n",
    "        df.set_value(i, 'total_retweets', tweet['metrics']['citations']['total'])\n",
    "        \n",
    "        #will sum and take max in post processing\n",
    "        df.set_value(i, 'sum_followers', tweet['author']['followers'])\n",
    "        df.set_value(i, 'max_followers', tweet['author']['followers'])\n",
    "        df.set_value(i, 'total_replies', tweet['metrics']['citations']['replies'])\n",
    "        df.set_value(i, 'total_ranking', tweet['metrics']['ranking_score'])\n",
    "        df.set_value(i, 'total_impressions', tweet['metrics']['impressions'])\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        if(mat_type is 'full'):\n",
    "            X[i, 0] = g.total_tweets.sum()\n",
    "            X[i, 1] = g.total_retweets.sum()\n",
    "            X[i, 2] = g.sum_followers.sum()\n",
    "            X[i, 3] = g.max_followers.max()\n",
    "            X[i, 4] = time_interval.hour     #store the hour of the day -> preserve order\n",
    "            X[i, 5] = g.total_replies.sum()\n",
    "            X[i, 6] = g.total_ranking.sum()\n",
    "            X[i, 7] = g.total_impressions.sum()\n",
    "        elif(mat_type is 'partial'):\n",
    "            X[i, 0] = g.total_tweets.sum()\n",
    "            X[i, 1] = g.total_retweets.sum()\n",
    "            X[i, 2] = g.sum_followers.sum()\n",
    "            X[i, 3] = g.max_followers.max()\n",
    "            X[i, 4] = time_interval.hour     #store the hour of the day -> preserve order\n",
    "\n",
    "            \n",
    "        y[i, 0] = g.total_tweets.sum()\n",
    "        \n",
    "    return np.nan_to_num(X[:-1]), y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def load_data(filename=None):\n",
    "    with open(filename, 'r') as file:\n",
    "        df = pd.DataFrame(index=range(num_tweets),\n",
    "                         columns=['date', 'total_tweets', 'total_retweets', 'sum_followers',\n",
    "                                 'max_followers', 'total_replies', 'total_ranking',\n",
    "                                 'total_impressions'])\n",
    "\n",
    "#total_tweets, total_retweets, sum_followers, \n",
    "#max_followers, time_of_day, toatl_replies, total_ranking, total_impressions\n",
    "        for i, l in tqdm.tqdm(enumerate(file), total=num_tweets):\n",
    "\n",
    "        #pandas df has first element as index and second as col\n",
    "            tweet = json.loads(l)\n",
    "\n",
    "            #get the date for sorting\n",
    "            date = datetime.datetime.fromtimestamp(tweet['firstpost_date'])\n",
    "            df.set_value(i, 'date', date)\n",
    "            df.set_value(i, 'total_tweets', 1)\n",
    "            df.set_value(i, 'total_retweets', tweet['metrics']['citations']['total'])\n",
    "\n",
    "            #will sum and take max in post processing\n",
    "            df.set_value(i, 'sum_followers', tweet['author']['followers'])\n",
    "            df.set_value(i, 'max_followers', tweet['author']['followers'])\n",
    "            df.set_value(i, 'total_replies', tweet['metrics']['citations']['replies'])\n",
    "            df.set_value(i, 'total_ranking', tweet['metrics']['ranking_score'])\n",
    "            df.set_value(i, 'total_impressions', tweet['metrics']['impressions'])\n",
    "\n",
    "        return df\n",
    "\n",
    "   # print('#%s' % hashtag)\n",
    "   # print('\\tAvg # of tweets / hour = %.3f' % (total_tweets / total_hours))\n",
    "   # print('\\tAvg # of followers / user = %.3f' % (total_followers / total_users))\n",
    "   # print('\\tAvg # of retweets / tweet = %.3f' % (total_retweets / total_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 799/188136 [00:00<00:23, 7987.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Hashtag:  gohawks  with ntweets:  188136\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188136/188136 [00:19<00:00, 9468.04it/s]\n",
      "  4%|▎         | 923/26232 [00:00<00:02, 9223.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Hashtag:  gopatriots  with ntweets:  26232\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26232/26232 [00:02<00:00, 9843.60it/s] \n",
      "  0%|          | 707/259024 [00:00<00:36, 7068.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Hashtag:  nfl  with ntweets:  259024\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259024/259024 [00:29<00:00, 8930.42it/s]\n",
      "  0%|          | 0/489713 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Hashtag:  patriots  with ntweets:  489713\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489713/489713 [00:49<00:00, 9795.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Hashtag:  sb49  with ntweets:  826951\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 462160/826951 [00:50<00:39, 9239.05it/s]"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for hashtag, num_tweets in hashtag_dict.items():\n",
    "    print(\"---\")\n",
    "    print(\"Hashtag: \", hashtag, \" with ntweets: \", num_tweets)\n",
    "    print(\"---\")\n",
    "    data[hashtag] = load_data(os.path.join('tweet_data','tweets_#' + hashtag +'.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [data['gohawks'], \n",
    "          data['gopatriots'], \n",
    "          data['nfl'], \n",
    "          data['patriots'], \n",
    "          data['sb49'], \n",
    "          data['superbowl']]\n",
    "frame_hashtags=['gohawks', 'gopatriots', 'nfl', 'patriots', 'sb49', 'superbowl']\n",
    "\n",
    "all_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verify that the dataframes are the right size\n",
    "print(data['gohawks'].shape)\n",
    "print(data['gopatriots'].shape)\n",
    "print(data['nfl'].shape)\n",
    "print(data['patriots'].shape)\n",
    "print(data['sb49'].shape)\n",
    "print(data['superbowl'].shape)\n",
    "\n",
    "assert(data['gohawks'].shape[0] == hashtag_dict['gohawks'])\n",
    "assert(data['gopatriots'].shape[0] == hashtag_dict['gopatriots'])\n",
    "assert(data['nfl'].shape[0] == hashtag_dict['nfl'])\n",
    "assert(data['patriots'].shape[0] == hashtag_dict['patriots'])\n",
    "assert(data['sb49'].shape[0] == hashtag_dict['sb49'])\n",
    "assert(data['superbowl'].shape[0] == hashtag_dict['superbowl'])\n",
    "\n",
    "\n",
    "print(all_data.shape)\n",
    "s=0\n",
    "for hashtag, ntweets in hashtag_dict.items():\n",
    "   s+=ntweets\n",
    "\n",
    "print(s)\n",
    "\n",
    "assert(all_data.shape[0] == s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Here, we show histograms with 1-hour bins that show the number the tweets in hour over time for two hashtag groups, #SuperBowl and #NFL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####TODO\n",
    "###TODO\n",
    "##TODO\n",
    "\n",
    "#frames_to_plot=[data['superbowl'], data['nfl']]\n",
    "frames_to_plot=[data['gopatriots']]\n",
    "for df in frames_to_plot:\n",
    "#    import pdb; pdb.set_trace() # debugging starts here\n",
    "    total_tweets = df.shape[0]\n",
    "    \n",
    "    min_utc = int(df['date'][df.index[0]].utcnow().strftime(\"%s\"))//3600*3600\n",
    "    #//3600*3600\n",
    "    max_utc = int(df['date'][df.index[-1]].utcnow().strftime(\"%s\"))//3600*3600\n",
    "    print(min_utc, max_utc)\n",
    "    bins = np.arange(min_utc, max_utc+3600, 3600)\n",
    "    x = []\n",
    "    for index, row in df.iterrows():\n",
    "       # print(row['date'].utcnow().strftime(\"%s\"))\n",
    "        x.append(int(row['date'].utcnow().strftime(\"%s\")))\n",
    "    n, b, p = plt.hist(x, bins, facecolor='g')\n",
    "#     print(b,p)\n",
    "    plt.xlabel('Hour (UTC)')\n",
    "    plt.ylabel('# of tweets')\n",
    "    plt.title('#' + hashtag)\n",
    "#     plt.axis([40, 160, 0, 0.03])\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.2\n",
    "For each hashtag, we first fitted a linear regression model using the following five features to\n",
    "predict the number of tweets in the next hour, with features extracted from tweet data in\n",
    "the previous hour.\n",
    "The features we used are:\n",
    "* Number of tweets (hashtag of interest)\n",
    "* Total number of retweets (hashtag of interest)\n",
    "* Sum of the number of followers of the users posting the hashtag\n",
    "* Maximum number of followers of the users posting the hashtag\n",
    "* Time of the day (which could take 24 values that represent hours of the day with respect to a given time zone)\n",
    "\n",
    "For each model, we present the mean squared error and r2 score. Further, we analyzed the significance of each feature using the t-test and P-value, using a third-party statsmodels.api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Mean squared error = 566824.371\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.498\n",
      "Model:                            OLS   Adj. R-squared:                  0.495\n",
      "Method:                 Least Squares   F-statistic:                     191.6\n",
      "Date:                Fri, 16 Mar 2018   Prob (F-statistic):          7.78e-142\n",
      "Time:                        13:26:13   Log-Likelihood:                -7818.7\n",
      "No. Observations:                 972   AIC:                         1.565e+04\n",
      "Df Residuals:                     967   BIC:                         1.567e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.2946      0.133      9.754      0.000       1.034       1.555\n",
      "x2            -0.1660      0.044     -3.801      0.000      -0.252      -0.080\n",
      "x3            -0.0002   6.48e-05     -2.676      0.008      -0.000   -4.62e-05\n",
      "x4          7.037e-05      0.000      0.584      0.559      -0.000       0.000\n",
      "x5             4.8688      1.892      2.573      0.010       1.155       8.583\n",
      "const               0          0        nan        nan           0           0\n",
      "x6                  0          0        nan        nan           0           0\n",
      "x7                  0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                     1700.263   Durbin-Watson:                   2.209\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          3686767.798\n",
      "Skew:                          11.016   Prob(JB):                         0.00\n",
      "Kurtosis:                     303.908   Cond. No.                          inf\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jonny/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1471: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n",
      "/Users/Jonny/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "/Users/Jonny/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Jonny/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/Jonny/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Mean squared error = 27345.569\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.660\n",
      "Model:                            OLS   Adj. R-squared:                  0.658\n",
      "Method:                 Least Squares   F-statistic:                     263.3\n",
      "Date:                Fri, 16 Mar 2018   Prob (F-statistic):          3.58e-156\n",
      "Time:                        13:26:13   Log-Likelihood:                -4458.0\n",
      "No. Observations:                 683   AIC:                             8926.\n",
      "Df Residuals:                     678   BIC:                             8949.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.9102      0.233     -3.913      0.000      -1.367      -0.454\n",
      "x2             1.8188      0.233      7.821      0.000       1.362       2.275\n",
      "x3            -0.0006      0.000     -2.801      0.005      -0.001      -0.000\n",
      "x4             0.0003      0.000      1.567      0.118   -7.64e-05       0.001\n",
      "x5            -0.0321      0.489     -0.066      0.948      -0.992       0.928\n",
      "const               0          0        nan        nan           0           0\n",
      "x6                  0          0        nan        nan           0           0\n",
      "x7                  0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                      470.173   Durbin-Watson:                   2.080\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           337818.087\n",
      "Skew:                           1.678   Prob(JB):                         0.00\n",
      "Kurtosis:                     111.901   Cond. No.                          inf\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\t Mean squared error = 217537.196\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.644\n",
      "Model:                            OLS   Adj. R-squared:                  0.642\n",
      "Method:                 Least Squares   F-statistic:                     332.8\n",
      "Date:                Fri, 16 Mar 2018   Prob (F-statistic):          1.55e-203\n",
      "Time:                        13:26:15   Log-Likelihood:                -7007.2\n",
      "No. Observations:                 926   AIC:                         1.402e+04\n",
      "Df Residuals:                     921   BIC:                         1.405e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.9383      0.131      7.142      0.000       0.680       1.196\n",
      "x2            -0.2501      0.065     -3.834      0.000      -0.378      -0.122\n",
      "x3          5.818e-05   2.06e-05      2.820      0.005    1.77e-05    9.87e-05\n",
      "x4         -3.562e-05    2.8e-05     -1.271      0.204   -9.06e-05    1.94e-05\n",
      "x5             3.8717      1.285      3.013      0.003       1.350       6.394\n",
      "const               0          0        nan        nan           0           0\n",
      "x6                  0          0        nan        nan           0           0\n",
      "x7                  0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                     1079.475   Durbin-Watson:                   2.292\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1415668.110\n",
      "Skew:                           4.735   Prob(JB):                         0.00\n",
      "Kurtosis:                     194.315   Cond. No.                          inf\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\t Mean squared error = 3382551.212\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.719\n",
      "Model:                            OLS   Adj. R-squared:                  0.717\n",
      "Method:                 Least Squares   F-statistic:                     498.7\n",
      "Date:                Fri, 16 Mar 2018   Prob (F-statistic):          1.05e-265\n",
      "Time:                        13:26:16   Log-Likelihood:                -8758.3\n",
      "No. Observations:                 980   AIC:                         1.753e+04\n",
      "Df Residuals:                     975   BIC:                         1.755e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.7781      0.080     22.181      0.000       1.621       1.935\n",
      "x2            -0.8579      0.067    -12.766      0.000      -0.990      -0.726\n",
      "x3             0.0002   2.19e-05      7.303      0.000       0.000       0.000\n",
      "x4         -7.153e-05    7.5e-05     -0.953      0.341      -0.000    7.57e-05\n",
      "x5             8.0908      4.665      1.734      0.083      -1.063      17.245\n",
      "const               0          0        nan        nan           0           0\n",
      "x6                  0          0        nan        nan           0           0\n",
      "x7                  0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                     1877.512   Durbin-Watson:                   1.712\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4320561.851\n",
      "Skew:                          13.564   Prob(JB):                         0.00\n",
      "Kurtosis:                     327.151   Cond. No.                          inf\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\t Mean squared error = 20100620.749\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.807\n",
      "Model:                            OLS   Adj. R-squared:                  0.806\n",
      "Method:                 Least Squares   F-statistic:                     483.8\n",
      "Date:                Fri, 16 Mar 2018   Prob (F-statistic):          1.10e-203\n",
      "Time:                        13:26:17   Log-Likelihood:                -5719.6\n",
      "No. Observations:                 582   AIC:                         1.145e+04\n",
      "Df Residuals:                     577   BIC:                         1.147e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.0904      0.099     10.999      0.000       0.896       1.285\n",
      "x2            -0.1175      0.091     -1.291      0.197      -0.296       0.061\n",
      "x3          3.653e-06   1.45e-05      0.253      0.801   -2.48e-05    3.21e-05\n",
      "x4             0.0001   4.77e-05      2.213      0.027    1.19e-05       0.000\n",
      "x5            -4.1655     15.345     -0.271      0.786     -34.303      25.972\n",
      "const               0          0        nan        nan           0           0\n",
      "x6                  0          0        nan        nan           0           0\n",
      "x7                  0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                     1171.838   Durbin-Watson:                   1.661\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2101434.987\n",
      "Skew:                          14.391   Prob(JB):                         0.00\n",
      "Kurtosis:                     295.965   Cond. No.                          inf\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Mean squared error = 42576118.849\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.786\n",
      "Model:                            OLS   Adj. R-squared:                  0.785\n",
      "Method:                 Least Squares   F-statistic:                     703.7\n",
      "Date:                Fri, 16 Mar 2018   Prob (F-statistic):          1.04e-317\n",
      "Time:                        13:26:19   Log-Likelihood:                -9824.9\n",
      "No. Observations:                 963   AIC:                         1.966e+04\n",
      "Df Residuals:                     958   BIC:                         1.968e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.3299      0.236      5.633      0.000       0.867       1.793\n",
      "x2             0.4026      0.117      3.434      0.001       0.173       0.633\n",
      "x3            -0.0002    1.2e-05    -20.299      0.000      -0.000      -0.000\n",
      "x4             0.0011   9.85e-05     11.032      0.000       0.001       0.001\n",
      "x5           -24.3155     17.329     -1.403      0.161     -58.322       9.691\n",
      "const               0          0        nan        nan           0           0\n",
      "x6                  0          0        nan        nan           0           0\n",
      "x7                  0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                     1747.162   Durbin-Watson:                   2.235\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4485126.325\n",
      "Skew:                          11.878   Prob(JB):                         0.00\n",
      "Kurtosis:                     336.488   Cond. No.                          inf\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import datetime, time\n",
    "import pytz\n",
    "from itertools import compress\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "\n",
    "pst_tz = pytz.timezone('US/Pacific')\n",
    "\n",
    "for df in frames:\n",
    "    X, y = build_matrix(df, mat_type='partial')\n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    print(\"\\t Mean squared error = %.3f\" % (mean_squared_error(y, y_pred)))\n",
    "    print(sm.OLS(y, X).fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From observing the significance, or p-value, of each feature, it is evident that the total number of tweets for the current hour is not a statistically significant feature as the p-value is larger than 0.05 (assuming alpha at 0.05). Every other feature, however, shows a low p-value, indicating that it contributes greatly our final prediction, and are therefore are valuable features. In general, a low p-value is evidence for the change in the predictor's value to be directly correlated to the change in the response variable, which is what we desire.\n",
    "\n",
    "Inutitively, this makes sense as the total tweets for the current hour would not affect the the total tweets for the next hour. Tweets do not become frequent when there is large number of tweets prior, instead, they become frequent when the previous tweets is associated with a large number of retweets and followers, signaling traction and actual social impact (at least virutally). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.3\n",
    "Design a regression model using any features from the papers you find or other new features you may find useful for this problem. Fit your model on the data of each hashtag and report fitting accuracy and significance of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first features we attempted to add were total number of \"favorites\" per hour, total number of replies per hour, and total number of verified tweeters posting that hour. The motivation for looking at the number of verified tweeters was the hypothesis that a verified public figure would be able to influence the number of tweets having to do with a subject he or she tweeted about. Most verified accounts are celebrities. For example, it's likely that if Tom Brady tweeted \"#gopatriots\", there would be more retweets and comments sharing this hashtag due to the network effect. It turned out that in the dataset, not many users are verified and the p-value indicated that this feature was not important. The model with these features added did signficantly worse and exhibited an R2-value of 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Mean squared error = 556864.412\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.507\n",
      "Model:                            OLS   Adj. R-squared:                  0.502\n",
      "Method:                 Least Squares   F-statistic:                     123.7\n",
      "Date:                Fri, 16 Mar 2018   Prob (F-statistic):          3.31e-142\n",
      "Time:                        13:26:21   Log-Likelihood:                -7810.0\n",
      "No. Observations:                 972   AIC:                         1.564e+04\n",
      "Df Residuals:                     964   BIC:                         1.567e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             7.6429      1.962      3.896      0.000       3.793      11.493\n",
      "x2            -0.2044      0.050     -4.071      0.000      -0.303      -0.106\n",
      "x3            -0.0003    9.5e-05     -3.451      0.001      -0.001      -0.000\n",
      "x4         -8.104e-05      0.000     -0.645      0.519      -0.000       0.000\n",
      "x5             3.6629      1.917      1.911      0.056      -0.099       7.425\n",
      "x6            -6.1694      7.168     -0.861      0.390     -20.237       7.898\n",
      "x7            -1.3654      0.424     -3.223      0.001      -2.197      -0.534\n",
      "x8             0.0002   7.52e-05      2.627      0.009    4.99e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     1827.334   Durbin-Watson:                   2.214\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4851359.955\n",
      "Skew:                          12.893   Prob(JB):                         0.00\n",
      "Kurtosis:                     348.140   Cond. No.                     9.36e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.36e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\t Mean squared error = 24981.940\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.689\n",
      "Model:                            OLS   Adj. R-squared:                  0.686\n",
      "Method:                 Least Squares   F-statistic:                     187.3\n",
      "Date:                Fri, 16 Mar 2018   Prob (F-statistic):          8.76e-166\n",
      "Time:                        13:26:21   Log-Likelihood:                -4427.2\n",
      "No. Observations:                 683   AIC:                             8870.\n",
      "Df Residuals:                     675   BIC:                             8907.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           -13.8469      1.804     -7.676      0.000     -17.389     -10.305\n",
      "x2             2.4871      0.240     10.352      0.000       2.015       2.959\n",
      "x3            -0.0016      0.000     -3.782      0.000      -0.002      -0.001\n",
      "x4             0.0008      0.000      3.181      0.002       0.000       0.001\n",
      "x5            -0.0682      0.471     -0.145      0.885      -0.992       0.856\n",
      "x6            -8.6841      3.681     -2.359      0.019     -15.911      -1.457\n",
      "x7             2.6665      0.368      7.248      0.000       1.944       3.389\n",
      "x8             0.0005      0.000      1.696      0.090   -7.67e-05       0.001\n",
      "==============================================================================\n",
      "Omnibus:                      760.450   Durbin-Watson:                   1.889\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           306948.952\n",
      "Skew:                           4.550   Prob(JB):                         0.00\n",
      "Kurtosis:                     106.456   Cond. No.                     3.28e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.28e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\t Mean squared error = 213628.897\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.650\n",
      "Model:                            OLS   Adj. R-squared:                  0.647\n",
      "Method:                 Least Squares   F-statistic:                     213.5\n",
      "Date:                Fri, 16 Mar 2018   Prob (F-statistic):          1.33e-203\n",
      "Time:                        13:26:22   Log-Likelihood:                -6998.3\n",
      "No. Observations:                 926   AIC:                         1.401e+04\n",
      "Df Residuals:                     918   BIC:                         1.405e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             5.9031      1.296      4.554      0.000       3.359       8.447\n",
      "x2            -0.2009      0.066     -3.052      0.002      -0.330      -0.072\n",
      "x3          4.882e-05    3.4e-05      1.437      0.151   -1.79e-05       0.000\n",
      "x4          -2.58e-05   2.81e-05     -0.920      0.358   -8.09e-05    2.92e-05\n",
      "x5             3.1047      1.307      2.376      0.018       0.540       5.670\n",
      "x6            -5.0117      3.185     -1.574      0.116     -11.262       1.239\n",
      "x7            -1.1149      0.289     -3.853      0.000      -1.683      -0.547\n",
      "x8          7.719e-06   2.59e-05      0.298      0.766   -4.32e-05    5.86e-05\n",
      "==============================================================================\n",
      "Omnibus:                     1115.581   Durbin-Watson:                   2.340\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1327222.741\n",
      "Skew:                           5.094   Prob(JB):                         0.00\n",
      "Kurtosis:                     188.189   Cond. No.                     1.10e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.1e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\t Mean squared error = 3303997.725\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.726\n",
      "Model:                            OLS   Adj. R-squared:                  0.723\n",
      "Method:                 Least Squares   F-statistic:                     321.1\n",
      "Date:                Fri, 16 Mar 2018   Prob (F-statistic):          9.87e-267\n",
      "Time:                        13:26:24   Log-Likelihood:                -8746.7\n",
      "No. Observations:                 980   AIC:                         1.751e+04\n",
      "Df Residuals:                     972   BIC:                         1.755e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             7.7411      1.266      6.115      0.000       5.257      10.226\n",
      "x2            -0.4992      0.102     -4.911      0.000      -0.699      -0.300\n",
      "x3             0.0005      0.000      3.260      0.001       0.000       0.001\n",
      "x4            -0.0003   9.34e-05     -3.611      0.000      -0.001      -0.000\n",
      "x5             7.4431      4.646      1.602      0.109      -1.675      16.561\n",
      "x6             2.7513      4.536      0.606      0.544      -6.151      11.654\n",
      "x7            -1.5844      0.336     -4.722      0.000      -2.243      -0.926\n",
      "x8            -0.0002      0.000     -1.228      0.220      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     1905.666   Durbin-Watson:                   1.736\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4520247.405\n",
      "Skew:                          14.030   Prob(JB):                         0.00\n",
      "Kurtosis:                     334.531   Cond. No.                     8.11e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 8.11e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Mean squared error = 18516861.767\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.822\n",
      "Model:                            OLS   Adj. R-squared:                  0.820\n",
      "Method:                 Least Squares   F-statistic:                     332.2\n",
      "Date:                Fri, 16 Mar 2018   Prob (F-statistic):          8.72e-210\n",
      "Time:                        13:26:25   Log-Likelihood:                -5696.0\n",
      "No. Observations:                 582   AIC:                         1.141e+04\n",
      "Df Residuals:                     574   BIC:                         1.144e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            12.9692      1.791      7.242      0.000       9.452      16.487\n",
      "x2             0.3982      0.116      3.423      0.001       0.170       0.627\n",
      "x3             0.0002    8.1e-05      2.049      0.041    6.91e-06       0.000\n",
      "x4          4.949e-05   5.93e-05      0.834      0.404    -6.7e-05       0.000\n",
      "x5             1.6699     15.047      0.111      0.912     -27.885      31.225\n",
      "x6           -13.8154      7.968     -1.734      0.083     -29.465       1.834\n",
      "x7            -3.0765      0.462     -6.658      0.000      -3.984      -2.169\n",
      "x8            -0.0001   8.06e-05     -1.625      0.105      -0.000    2.74e-05\n",
      "==============================================================================\n",
      "Omnibus:                     1145.750   Durbin-Watson:                   1.728\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2135236.482\n",
      "Skew:                          13.625   Prob(JB):                         0.00\n",
      "Kurtosis:                     298.480   Cond. No.                     1.04e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.04e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\t Mean squared error = 40498445.505\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.796\n",
      "Model:                            OLS   Adj. R-squared:                  0.795\n",
      "Method:                 Least Squares   F-statistic:                     467.1\n",
      "Date:                Fri, 16 Mar 2018   Prob (F-statistic):          4.94e-324\n",
      "Time:                        13:26:28   Log-Likelihood:                -9800.8\n",
      "No. Observations:                 963   AIC:                         1.962e+04\n",
      "Df Residuals:                     955   BIC:                         1.966e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           -11.7704      2.820     -4.173      0.000     -17.305      -6.235\n",
      "x2             0.6362      0.121      5.256      0.000       0.399       0.874\n",
      "x3             0.0008      0.000      3.732      0.000       0.000       0.001\n",
      "x4             0.0010      0.000      9.921      0.000       0.001       0.001\n",
      "x5           -11.8030     17.077     -0.691      0.490     -45.315      21.709\n",
      "x6            58.3133     17.813      3.274      0.001      23.356      93.270\n",
      "x7             2.7623      0.600      4.603      0.000       1.585       3.940\n",
      "x8            -0.0011      0.000     -4.951      0.000      -0.002      -0.001\n",
      "==============================================================================\n",
      "Omnibus:                     1920.101   Durbin-Watson:                   2.088\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          5295072.478\n",
      "Skew:                          14.773   Prob(JB):                         0.00\n",
      "Kurtosis:                     365.066   Cond. No.                     1.16e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.16e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import datetime, time\n",
    "import pytz\n",
    "from itertools import compress\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "\n",
    "pst_tz = pytz.timezone('US/Pacific')\n",
    "\n",
    "for df in frames:\n",
    "    X, y = build_matrix(df, mat_type='full')\n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    print(\"\\t Mean squared error = %.3f\" % (mean_squared_error(y, y_pred)))\n",
    "    print(sm.OLS(y, X).fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we initially started with the following features:\n",
    "- total number of favorites per hour\n",
    "- total number of replies per hour\n",
    "- total number of verified tweeters that hour\n",
    "\n",
    "Favorites and verified tweets were ineffective features. There are very few verified accounts so it resulted in sparsity and not much information gain. The number of favorites was also pretty low. The total number of replies seemed to improve performance, so we left it in. The next test involved the following three features, after having removed favorites and verified tweeters:\n",
    "- total number of replies per hour\n",
    "- total ranking \n",
    "- total impressions\n",
    "\n",
    "Ranking and impressions indicate the popularity or visibility of a tweet/tweeter, so these seemed like reasonable additions. These features improved RMSE performance by several points in terms of R2, and were vastly more effective than the previously added sparse features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.4\n",
    "In this part, we would like to perform 10-fold cross-validation on the models from the previous part and calculate the average prediction error over samples in the held-out part for the 10 tests. For this problem, you should split the feature data (your set of (features, predictant) pairs for windows) into 10 parts to perform cross-validation. Also, your evaluated error should be of the form |Npredicted − Nreal|.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error #RMSE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def cv(X, y, model, n_splits=10, verbose=True, display_last_ols=False):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    rmses = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        y_train = y_train.ravel()\n",
    "        y_test = y_test.ravel()\n",
    "        #print(sm.OLS(y, X).fit().summary())\n",
    "#        print(X_train.shape)\n",
    "#        print(y_train.shape)\n",
    "        if(model == 'lr'):\n",
    "            lr = sm.OLS(y_train, X_train).fit()\n",
    "            y_preds = lr.predict(X_test)\n",
    "        elif(model == 'rf'):\n",
    "            rf = RandomForestRegressor()\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_preds = rf.predict(X_test)\n",
    "        elif(model == 'mlp'):\n",
    "            mlp = MLPRegressor()\n",
    "            mlp.fit(X_train, y_train)\n",
    "            y_preds = mlp.predict(X_test)\n",
    "        \n",
    "        rmses.append(mean_squared_error(y_test, y_preds))\n",
    "        \n",
    "        \n",
    "    if verbose: \n",
    "        print(\"Errors from CV are: \", rmses)\n",
    "        print(\"Averaged error is: \", np.mean(rmses))\n",
    "        if model is 'lr':\n",
    "            print(lr.summary())\n",
    "        \n",
    "    return rmses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#datetime args: Attributes: year, month, day, hour, minute, second, microsecond, and tzinfo.\n",
    "#before Feb 1, 8:00am\n",
    "first_date_marker = datetime.datetime(2015, 2, 1, 8, 0, 0, 0)\n",
    "\n",
    "#end at 8pm\n",
    "second_date_marker = datetime.datetime(2015, 2, 1, 20, 0, 0, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_and_test(df, model, verbose=True):\n",
    "    ###Set up the data by filtering via index\n",
    "    #Before Feb. 1, 8:00 a.m.\n",
    "    #sort out the times in the dataframe before this period\n",
    "    df_p1 = df[df.date < first_date_marker]\n",
    "\n",
    "\n",
    "    #Between Feb. 1, 8:00 a.m. and 8:00 p.m. \n",
    "    df_p2 = df[(df.date > first_date_marker) &\n",
    "               (df.date < second_date_marker)]\n",
    "\n",
    "    #After Feb. 1, 8:00 p.m.\n",
    "    df_p3 = df[df.date > second_date_marker]\n",
    "\n",
    "#    print(\"Before Feb. 1, 8:00 a.m.\")\n",
    "    X_df_p1, y_df_p1 = build_matrix(df_p1, index='date')\n",
    "    errors_df_p1 = cv(X_df_p1, y_df_p1, model, verbose=verbose) #default splits = 10 no need to specify\n",
    "   # print(\"Average cv error: \", np.mean(errors_df_p1))\n",
    "    \n",
    " #   print(\"Between Feb. 1, 8:00 a.m. and 8:00 p.m.\")\n",
    "    X_df_p2, y_df_p2 = build_matrix(df_p2, index='date')\n",
    "    errors_df_p2 = cv(X_df_p2, y_df_p2, model,verbose=verbose)\n",
    "  #  print(\"Average cv error: \", np.mean(errors_df_p2))\n",
    "    \n",
    "  #  print(\"After Feb. 1, 8:00 p.m.\")\n",
    "    X_df_p3, y_df_p3 = build_matrix(df_p3, index='date')\n",
    "    errors_df_p3 = cv(X_df_p3, y_df_p3, model,verbose=verbose)\n",
    "   # print(\"Average cv error: \", np.mean(errors_df_p3))\n",
    "\n",
    "    return np.mean(errors_df_p1), np.mean(errors_df_p2), np.mean(errors_df_p3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Hashtag Performance with 3 Models\n",
    "For each hashtag, report the average cross-validation errors for the 3 different models. Note that you should do the 90-10% splitting for each model within its specific time window. I.e. Only use data within one of the 3 periods above for training and testing each time, so for each period you will run 10 tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return True;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return True;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "\n",
    "models = ['lr', 'rf', 'mlp']\n",
    "results = {}\n",
    "for model in models:\n",
    "    print(\"Model is: \"+model)\n",
    "    i = 0\n",
    "    p1_errs, p2_errs, p3_errs = [],[],[]\n",
    "    for df in frames:\n",
    "        err_p1, err_p2, err_p3 = filter_and_test(df, model, verbose=False)\n",
    "#        print(\"Hashtag: \", frame_hashtags[i])\n",
    " #       print(\"Period 1 avg. cv error: \", err_p1)\n",
    "  #      print(\"Period 2 avg. cv error: \", err_p2)\n",
    "   #     print(\"Period 3 avg. cv error: \", err_p3)\n",
    "        p1_errs.append(err_p1)\n",
    "        p2_errs.append(err_p2)\n",
    "        p3_errs.append(err_p3)\n",
    "        i+=1\n",
    "    results[model] = [np.mean(p1_errs), np.mean(p2_errs), np.mean(p3_errs)]\n",
    "            \n",
    "#            full_errors = cv(X_full, y_full, n_splits=10)\n",
    " #           print(\"Errors from full set CV: \", full_errors)\n",
    "  #          print(\"Mean error from CV: \", np.mean(full_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
