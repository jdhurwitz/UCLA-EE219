{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity Prediction\n",
    "## Problem 1.1\n",
    "As a preliminary step, we calculated the following statistics to get a holistic overview of the twitter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline \n",
    "\n",
    "data_dir = 'tweet_data' # MAKE SURE TO CHANGE THIS TO WHERE EVER YOUR DATA IS. \n",
    "# The total data size is ~14gb which is too large to be committed into github\n",
    "\n",
    "# Puts data into dict\n",
    "# hashtags = ['gohawks', 'gopatriots', 'nfl', 'patriots', 'sb49', 'superbowl'] \n",
    "# this takes awhile so use toy example of #gopatriots only\n",
    "hashtags = ['gopatriots']\n",
    "data = {}\n",
    "for hashtag in hashtags:\n",
    "    file_name = data_dir + '/tweets_#' + hashtag + '.txt' \n",
    "    with open(file_name, 'r') as f:\n",
    "        tweets = []\n",
    "        for i, l in enumerate(f):\n",
    "            tweet = json.loads(l)\n",
    "            tweets.append(tweet)\n",
    "        data[hashtag] = tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(data['gopatriots'][0])\n",
    "#print(data['gopatriots'][0]['metrics']['impressions'])\n",
    "#for item in data['gopatriots'][0].items():\n",
    " #   print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#gopatriots\n",
      "\tAvg # of tweets / hour = 46.346\n",
      "\tAvg # of followers / user = 1298.824\n",
      "\tAvg # of retweets / tweet = 1.400\n"
     ]
    }
   ],
   "source": [
    "for hashtag in hashtags:\n",
    "    total_tweets = len(data[hashtag])\n",
    "    min_utc = data[hashtag][0]['citation_date']\n",
    "    max_utc = data[hashtag][-1]['citation_date']\n",
    "    total_hours = (max_utc - min_utc) // 3600\n",
    "    \n",
    "    total_retweets = 0\n",
    "    \n",
    "    total_followers = 0\n",
    "    users = {}\n",
    "    for tweet in data[hashtag]:\n",
    "        user_id = tweet['tweet']['user']['id']\n",
    "        total_retweets += tweet['metrics']['citations']['total']\n",
    "        if user_id in users: continue # user already encountered\n",
    "        users[user_id] = True\n",
    "        total_followers += tweet['author']['followers']\n",
    "    total_users = len(users)\n",
    "    \n",
    "    print('#%s' % hashtag)\n",
    "    print('\\tAvg # of tweets / hour = %.3f' % (total_tweets / total_hours))\n",
    "    print('\\tAvg # of followers / user = %.3f' % (total_followers / total_users))\n",
    "    print('\\tAvg # of retweets / tweet = %.3f' % (total_retweets / total_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Here, we show histograms with 1-hour bins that show the number the tweets in hour over time for two hashtag groups, #SuperBowl and #NFL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c5746a7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime, time\n",
    "import pytz\n",
    "hashtag_dict = {}\n",
    "for hashtag in hashtags:\n",
    "    total_tweets = len(data[hashtag])\n",
    "    hashtag_dict[hashtag] = total_tweets\n",
    "    min_utc = data[hashtag][0]['citation_date']//3600*3600\n",
    "    max_utc = data[hashtag][-1]['citation_date']//3600*3600\n",
    "#     print(min_utc, max_utc)\n",
    "    bins = np.arange(min_utc, max_utc+3600, 3600)\n",
    "    x = []\n",
    "    for tweet in data[hashtag]:\n",
    "        x.append(tweet['citation_date'])\n",
    "    \n",
    "    n, b, p = plt.hist(x, bins, facecolor='g')\n",
    "#     print(b,p)\n",
    "    plt.xlabel('Hour (UTC)')\n",
    "    plt.ylabel('# of tweets')\n",
    "    plt.title('#' + hashtag)\n",
    "#     plt.axis([40, 160, 0, 0.03])\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.2\n",
    "For each hashtag, we first fitted a linear regression model using the following five features to\n",
    "predict the number of tweets in the next hour, with features extracted from tweet data in\n",
    "the previous hour.\n",
    "The features we used are:\n",
    "* Number of tweets (hashtag of interest)\n",
    "* Total number of retweets (hashtag of interest)\n",
    "* Sum of the number of followers of the users posting the hashtag\n",
    "* Maximum number of followers of the users posting the hashtag\n",
    "* Time of the day (which could take 24 values that represent hours of the day with respect to a given time zone)\n",
    "\n",
    "For each model, we present the training accuracy and r2 score. Further, we analyzed the significance of each feature using the t-test and P-value, using a third-party statsmodels.api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441, 5) (441,)\n",
      "#gopatriots\n",
      "\t Mean squared error = 38740.916\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.686\n",
      "Model:                            OLS   Adj. R-squared:                  0.683\n",
      "Method:                 Least Squares   F-statistic:                     190.9\n",
      "Date:                Fri, 09 Mar 2018   Prob (F-statistic):          2.13e-107\n",
      "Time:                        15:55:17   Log-Likelihood:                -2955.6\n",
      "No. Observations:                 441   AIC:                             5921.\n",
      "Df Residuals:                     436   BIC:                             5942.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.2907      0.264      1.100      0.272      -0.229       0.810\n",
      "x2            -0.7146      0.267     -2.680      0.008      -1.239      -0.191\n",
      "x3             0.0018      0.000      8.143      0.000       0.001       0.002\n",
      "x4            -0.0018      0.000     -8.471      0.000      -0.002      -0.001\n",
      "x5             1.7018      0.732      2.326      0.020       0.264       3.140\n",
      "==============================================================================\n",
      "Omnibus:                      460.665   Durbin-Watson:                   1.834\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           120060.211\n",
      "Skew:                           3.905   Prob(JB):                         0.00\n",
      "Kurtosis:                      83.454   Cond. No.                     3.18e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.18e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import datetime, time\n",
    "import pytz\n",
    "from itertools import compress\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "\n",
    "pst_tz = pytz.timezone('US/Pacific')\n",
    "\n",
    "for hashtag in hashtags:\n",
    "    total_tweets = len(data[hashtag])\n",
    "    min_utc = data[hashtag][0]['citation_date']//3600*3600\n",
    "    max_utc = data[hashtag][-1]['citation_date']//3600*3600\n",
    "    bins = np.arange(min_utc, max_utc+3600, 3600) # [0, 5, 10, 15]\n",
    "    \n",
    "#     X = np.zeros((len(bins) - 2, 6))\n",
    "    bin_data = {}\n",
    "\n",
    "    post_times = [tweet['citation_date'] for tweet in data[hashtag]]\n",
    "    inds = np.digitize(post_times, bins)\n",
    "    for i in range(total_tweets):\n",
    "        bin_num = inds[i] # tweet is in this bin num : bins[inds[n]-1] <= tweet < bins[inds[n]]\n",
    "        t = (inds == bin_num)\n",
    "        tweet_inds = list(compress(range(len(t)), t))\n",
    "        \n",
    "        total_tweets, total_retweets, user_followers, time_of_day = 0, 0, {}, datetime.datetime.fromtimestamp(bins[bin_num-1], pst_tz).hour\n",
    "        for j in tweet_inds:\n",
    "            tweet = data[hashtag][j]\n",
    "            total_tweets += 1\n",
    "            total_retweets += tweet['metrics']['citations']['total']\n",
    "            user_id = tweet['tweet']['user']['id']\n",
    "            if user_id in user_followers: continue # user already encountered\n",
    "            user_followers[user_id] = tweet['author']['followers']\n",
    "#         print((total_tweets, total_retweets, np.sum(list(user_followers.values())), np.amax(list(user_followers.values())), time_of_day))\n",
    "        bin_data[bin_num] = (total_tweets, total_retweets, int(np.sum(list(user_followers.values()))), int(np.amax(list(user_followers.values()))), time_of_day)\n",
    "    \n",
    "    rows = []\n",
    "    for b, d in bin_data.items():\n",
    "        rows.append(np.array(list(d) + [bin_data[b+1][0] if b+1 in bin_data else 0]))\n",
    "    X = np.stack(rows)\n",
    "    y = X[:,-1]\n",
    "    X = X[:,0:5]\n",
    "    print(X.shape, y.shape)\n",
    "    \n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    print(\"#\" + hashtag)\n",
    "    print(\"\\t Mean squared error = %.3f\" % (mean_squared_error(y, y_pred)))\n",
    "    print(sm.OLS(y, X).fit().summary())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From observing the significance, or p-value, of each feature, it is evident that the total number of tweets for the current hour is not a statistically significant feature as the p-value is larger than 0.05 (assuming alpha at 0.05). Every other feature, however, shows a low p-value, indicating that it contributes greatly our final prediction, and are therefore are valuable features. In general, a low p-value is evidence for the change in the predictor's value to be directly correlated to the change in the response variable, which is what we desire.\n",
    "\n",
    "Inutitively, this makes sense as the total tweets for the current hour would not affect the the total tweets for the next hour. Tweets do not become frequent when there is large number of tweets prior, instead, they become frequent when the previous tweets is associated with a large number of retweets and followers, signaling traction and actual social impact (at least virutally). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.3\n",
    "Design a regression model using any features from the papers you find or other new features you may find useful for this problem. Fit your model on the data of each hashtag and report fitting accuracy and significance of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first features we attempted to add were total number of \"favorites\" per hour, total number of replies per hour, and total number of verified tweeters posting that hour. The motivation for looking at the number of verified tweeters was the hypothesis that a verified public figure would be able to influence the number of tweets having to do with a subject he or she tweeted about. Most verified accounts are celebrities. For example, it's likely that if Tom Brady tweeted \"#gopatriots\", there would be more retweets and comments sharing this hashtag due to the network effect. It turned out that in the dataset, not many users are verified and the p-value indicated that this feature was not important. The model with these features added did signficantly worse and exhibited an R2-value of 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import datetime, time\n",
    "import pytz\n",
    "from itertools import compress\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "\n",
    "pst_tz = pytz.timezone('US/Pacific')\n",
    "\n",
    "#for hashtag in hashtags:\n",
    "total_tweets = len(data[hashtag])\n",
    "min_utc = data[hashtag][0]['citation_date']//3600*3600\n",
    "max_utc = data[hashtag][-1]['citation_date']//3600*3600\n",
    "bins = np.arange(min_utc, max_utc+3600, 3600) # [0, 5, 10, 15]\n",
    "\n",
    "#     X = np.zeros((len(bins) - 2, 6))\n",
    "bin_data = {}\n",
    "\n",
    "post_times = [tweet['citation_date'] for tweet in data[hashtag]]\n",
    "inds = np.digitize(post_times, bins)\n",
    "for i in range(total_tweets):\n",
    "    bin_num = inds[i] # tweet is in this bin num : bins[inds[n]-1] <= tweet < bins[inds[n]]\n",
    "    t = (inds == bin_num)\n",
    "    tweet_inds = list(compress(range(len(t)), t))\n",
    "\n",
    "    total_tweets, total_retweets, user_followers, time_of_day = 0, 0, {}, datetime.datetime.fromtimestamp(bins[bin_num-1], pst_tz).hour\n",
    "    total_replies, total_ranking, total_impressions = 0, 0, 0\n",
    "    for j in tweet_inds:\n",
    "        tweet = data[hashtag][j]\n",
    "        total_tweets += 1\n",
    "        total_retweets += tweet['metrics']['citations']['total']\n",
    "        user_id = tweet['tweet']['user']['id']\n",
    "        \n",
    "        total_replies += tweet['metrics']['citations']['replies']\n",
    "        total_ranking += tweet['metrics']['ranking_score']\n",
    "        total_impressions += tweet['metrics']['impressions']\n",
    "        \n",
    "        \n",
    "\n",
    "        if user_id in user_followers: continue # user already encountered\n",
    "        user_followers[user_id] = tweet['author']['followers']\n",
    "#         print((total_tweets, total_retweets, np.sum(list(user_followers.values())), np.amax(list(user_followers.values())), time_of_day))\n",
    "    bin_data[bin_num] = (total_tweets, total_retweets, int(np.sum(list(user_followers.values()))), \n",
    "                         int(np.amax(list(user_followers.values()))), time_of_day,\n",
    "                        total_replies, total_ranking, total_impressions)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441, 8) (441,)\n",
      "#gopatriots\n",
      "\t Mean squared error = 32097.153\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.740\n",
      "Model:                            OLS   Adj. R-squared:                  0.735\n",
      "Method:                 Least Squares   F-statistic:                     154.2\n",
      "Date:                Fri, 09 Mar 2018   Prob (F-statistic):          1.31e-121\n",
      "Time:                        15:58:43   Log-Likelihood:                -2914.2\n",
      "No. Observations:                 441   AIC:                             5844.\n",
      "Df Residuals:                     433   BIC:                             5877.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           -11.4841      1.953     -5.880      0.000     -15.323      -7.646\n",
      "x2            -0.8573      0.256     -3.348      0.001      -1.361      -0.354\n",
      "x3             0.0039      0.000     12.326      0.000       0.003       0.004\n",
      "x4            -0.0018      0.000     -7.780      0.000      -0.002      -0.001\n",
      "x5             1.8499      0.671      2.757      0.006       0.531       3.169\n",
      "x6            -1.8950      4.261     -0.445      0.657     -10.270       6.480\n",
      "x7             2.5946      0.413      6.288      0.000       1.784       3.406\n",
      "x8            -0.0020      0.000     -7.841      0.000      -0.002      -0.001\n",
      "==============================================================================\n",
      "Omnibus:                      463.218   Durbin-Watson:                   1.831\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            97132.682\n",
      "Skew:                           4.028   Prob(JB):                         0.00\n",
      "Kurtosis:                      75.258   Cond. No.                     3.08e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.08e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for b, d in bin_data.items():\n",
    "    rows.append(np.array(list(d) + [bin_data[b+1][0] if b+1 in bin_data else 0]))\n",
    "X = np.stack(rows)\n",
    "y = X[:,-1]\n",
    "X = X[:,0:8]\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X, y)\n",
    "y_pred = lr.predict(X)\n",
    "print(\"#\" + hashtag)\n",
    "print(\"\\t Mean squared error = %.3f\" % (mean_squared_error(y, y_pred)))\n",
    "print(sm.OLS(y, X).fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we initially started with the following features:\n",
    "- total number of favorites per hour\n",
    "- total number of replies per hour\n",
    "- total number of verified tweeters that hour\n",
    "\n",
    "Favorites and verified tweets were ineffective features. There are very few verified accounts so it resulted in sparsity and not much information gain. The number of favorites was also pretty low. The total number of replies seemed to improve performance, so we left it in. The next test involved the following three features, after having removed favorites and verified tweeters:\n",
    "- total number of replies per hour\n",
    "- total ranking \n",
    "- total impressions\n",
    "\n",
    "Ranking and impressions indicate the popularity or visibility of a tweet/tweeter, so these seemed like reasonable additions. These features improved RMSE performance by several points in terms of R2, and were vastly more effective than the previously added sparse features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.4\n",
    "In this part, we would like to perform 10-fold cross-validation on the models from the previous part and calculate the average prediction error over samples in the held-out part for the 10 tests. For this problem, you should split the feature data (your set of (features, predictant) pairs for windows) into 10 parts to perform cross-validation. Also, your evaluated error should be of the form |Npredicted − Nreal|.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error #RMSE\n",
    "\n",
    "def cv(X, y, n_splits=10, verbose=True, display_last_ols=True):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    rmses = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        #print(sm.OLS(y, X).fit().summary())\n",
    "        lr = sm.OLS(y_train, X_train).fit()\n",
    "        y_preds = lr.predict(X_test)\n",
    "        \n",
    "        rmses.append(mean_squared_error(y_test, y_preds))\n",
    "    if display_last_ols:\n",
    "        print(lr.summary())\n",
    "        \n",
    "    if verbose: \n",
    "        print(\"Errors from CV are: \", rmses)\n",
    "        print(\"Averaged error is: \", np.mean(rmses))\n",
    "        \n",
    "    return rmses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_matrix(raw_df, index='date'):\n",
    "    \"\"\"\n",
    "    Iterates through the rows of the created dataframe and performs summing, maxes, and \n",
    "    creates time series\n",
    "    \"\"\"\n",
    "    raw_df = raw_df.set_index(index)\n",
    "    time_series = raw_df.groupby(pd.TimeGrouper(freq='60Min'))\n",
    "    \n",
    "    X = np.zeros((len(time_series), 8))\n",
    "    y = np.zeros((len(time_series), 1))\n",
    "    for i, (time_interval, g) in enumerate(time_series):\n",
    "        \"\"\"\n",
    "        #get the date for sorting\n",
    "        date = datetime.fromtimestamp(tweet_data['firstpost_date'])\n",
    "        df.set_value(i, 'date', date)\n",
    "        df.set_value(i, 'total_tweets', 1)\n",
    "        df.set_value(i, 'total_retweets', tweet['metrics']['citations']['total'])\n",
    "        \n",
    "        #will sum and take max in post processing\n",
    "        df.set_value(i, 'sum_followers', tweet['author']['followers'])\n",
    "        df.set_value(i, 'max_followers', tweet['author']['followers'])\n",
    "        df.set_value(i, 'total_replies', tweet['metrics']['citations']['replies'])\n",
    "        df.set_value(i, 'total_ranking', tweet['metrics']['ranking_score'])\n",
    "        df.set_value(i, 'total_impressions', tweet['metrics']['impressions'])\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        X[i, 0] = g.total_tweets.sum()\n",
    "        X[i, 1] = g.total_retweets.sum()\n",
    "        X[i, 2] = g.sum_followers.sum()\n",
    "        X[i, 3] = g.max_followers.max()\n",
    "        X[i, 4] = time_interval.hour     #store the hour of the day -> preserve order\n",
    "        X[i, 5] = g.total_replies.sum()\n",
    "        X[i, 6] = g.total_ranking.sum()\n",
    "        X[i, 7] = g.total_impressions.sum()\n",
    "        \n",
    "        y[i, 0] = g.total_tweets.sum()\n",
    "        \n",
    "    return np.nan_to_num(X[:-1]), y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-14 09:00:00-08:00\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import datetime, time\n",
    "import pytz\n",
    "from itertools import compress\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "\n",
    "pst_tz = pytz.timezone('US/Pacific')\n",
    "\n",
    "#for hashtag in hashtags:\n",
    "total_tweets = len(data[hashtag])\n",
    "min_utc = data[hashtag][0]['citation_date']//3600*3600\n",
    "max_utc = data[hashtag][-1]['citation_date']//3600*3600\n",
    "bins = np.arange(min_utc, max_utc+3600, 3600) # [0, 5, 10, 15]\n",
    "\n",
    "\n",
    "print(datetime.datetime.fromtimestamp(min_utc, pst_tz))\n",
    "#datetime args: Attributes: year, month, day, hour, minute, second, microsecond, and tzinfo.\n",
    "#before Feb 1, 8:00am\n",
    "first_date_marker = datetime.datetime(2015, 2, 1, 8, 0, 0, 0)\n",
    "\n",
    "#end at 8pm\n",
    "second_date_marker = datetime.datetime(2015, 2, 1, 20, 0, 0, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_and_test(df):\n",
    "    ###Set up the data by filtering via index\n",
    "    #Before Feb. 1, 8:00 a.m.\n",
    "    #sort out the times in the dataframe before this period\n",
    "    df_p1 = df[df.date < first_date_marker]\n",
    "\n",
    "\n",
    "    #Between Feb. 1, 8:00 a.m. and 8:00 p.m. \n",
    "    df_p2 = df[(df.date > first_date_marker) &\n",
    "               (df.date < second_date_marker)]\n",
    "\n",
    "    #After Feb. 1, 8:00 p.m.\n",
    "    df_p3 = df[df.date > second_date_marker]\n",
    "\n",
    "    print(\"Before Feb. 1, 8:00 a.m.\")\n",
    "    X_df_p1, y_df_p1 = build_matrix(df_p1, index='date')\n",
    "    errors_df_p1 = cv(X_df_p1, y_df_p1) #default splits = 10 no need to specify\n",
    "\n",
    "    print(\"Between Feb. 1, 8:00 a.m. and 8:00 p.m.\")\n",
    "    X_df_p2, y_df_p2 = build_matrix(df_p2, index='date')\n",
    "    errors_df_p2 = cv(X_df_p2, y_df_p2)\n",
    "\n",
    "    print(\"After Feb. 1, 8:00 p.m.\")\n",
    "    X_df_p3, y_df_p3 = build_matrix(df_p3, index='date')\n",
    "    errors_df_p3 = cv(X_df_p3, y_df_p3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Hashtag Performance with 3 Models\n",
    "For each hashtag, report the average cross-validation errors for the 3 different models. Note that you should do the 90-10% splitting for each model within its specific time window. I.e. Only use data within one of the 3 periods above for training and testing each time, so for each period you will run 10 tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/26232 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Hashtag:  gopatriots\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26232/26232 [00:02<00:00, 10026.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Feb. 1, 8:00 a.m.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.630\n",
      "Model:                            OLS   Adj. R-squared:                  0.624\n",
      "Method:                 Least Squares   F-statistic:                     103.2\n",
      "Date:                Fri, 09 Mar 2018   Prob (F-statistic):           1.31e-99\n",
      "Time:                        15:58:46   Log-Likelihood:                -2538.7\n",
      "No. Observations:                 493   AIC:                             5093.\n",
      "Df Residuals:                     485   BIC:                             5127.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             6.4784      2.466      2.627      0.009       1.633      11.323\n",
      "x2             0.0137      0.150      0.091      0.927      -0.281       0.308\n",
      "x3            -0.0019      0.000     -5.726      0.000      -0.003      -0.001\n",
      "x4             0.0019      0.000      8.030      0.000       0.001       0.002\n",
      "x5            -0.2524      0.164     -1.541      0.124      -0.574       0.069\n",
      "x6             1.4787      1.884      0.785      0.433      -2.224       5.181\n",
      "x7            -0.8167      0.499     -1.637      0.102      -1.797       0.163\n",
      "x8         -2.658e-05      0.000     -0.226      0.821      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      759.385   Durbin-Watson:                   1.972\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           370641.523\n",
      "Skew:                           8.218   Prob(JB):                         0.00\n",
      "Kurtosis:                     136.316   Cond. No.                     4.03e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.03e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Errors from CV are:  [10.694077661294902, 11.163409861398719, 14.829019885209823, 10252.185794896926, 11910.651520773967, 37.296861914597855, 1241.0893042809769, 336.42794536395826, 68.731526617074564, 153.3974182715902]\n",
      "Averaged error is:  2403.64668795\n",
      "Between Feb. 1, 8:00 a.m. and 8:00 p.m.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.750\n",
      "Method:                 Least Squares   F-statistic:                     4.753\n",
      "Date:                Fri, 09 Mar 2018   Prob (F-statistic):              0.185\n",
      "Time:                        15:58:46   Log-Likelihood:                -75.367\n",
      "No. Observations:                  10   AIC:                             166.7\n",
      "Df Residuals:                       2   BIC:                             169.2\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           297.7770    158.016      1.884      0.200    -382.110     977.664\n",
      "x2            -9.1687      5.893     -1.556      0.260     -34.525      16.187\n",
      "x3             0.0800      0.065      1.235      0.342      -0.199       0.359\n",
      "x4            -0.0121      0.007     -1.675      0.236      -0.043       0.019\n",
      "x5           -29.5580    114.470     -0.258      0.820    -522.084     462.968\n",
      "x6           855.4949    597.483      1.432      0.289   -1715.267    3426.257\n",
      "x7           -61.6203     32.723     -1.883      0.200    -202.415      79.174\n",
      "x8            -0.0755      0.063     -1.196      0.354      -0.347       0.196\n",
      "==============================================================================\n",
      "Omnibus:                        2.972   Durbin-Watson:                   2.455\n",
      "Prob(Omnibus):                  0.226   Jarque-Bera (JB):                1.544\n",
      "Skew:                          -0.950   Prob(JB):                        0.462\n",
      "Kurtosis:                       2.690   Cond. No.                     5.97e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.97e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Errors from CV are:  [20664677.012114398, 39603901.581337824, 21676923.910048008, 523705.38405767444, 3038297.6346605821, 9694198.660976721, 756213567693.12939, 55046493.14200417, 67727673.706404507, 726730671.66225386]\n",
      "Averaged error is:  75715827423.6\n",
      "After Feb. 1, 8:00 p.m.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.960\n",
      "Model:                            OLS   Adj. R-squared:                  0.957\n",
      "Method:                 Least Squares   F-statistic:                     308.6\n",
      "Date:                Fri, 09 Mar 2018   Prob (F-statistic):           2.44e-68\n",
      "Time:                        15:58:46   Log-Likelihood:                -276.94\n",
      "No. Observations:                 111   AIC:                             569.9\n",
      "Df Residuals:                     103   BIC:                             591.5\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -2.1226      0.519     -4.094      0.000      -3.151      -1.094\n",
      "x2            -0.0761      0.145     -0.525      0.601      -0.364       0.212\n",
      "x3            -0.0012      0.000     -2.780      0.006      -0.002      -0.000\n",
      "x4             0.0016      0.000      9.019      0.000       0.001       0.002\n",
      "x5             0.0144      0.024      0.604      0.547      -0.033       0.062\n",
      "x6            -4.7004      1.490     -3.154      0.002      -7.656      -1.745\n",
      "x7             0.8364      0.101      8.270      0.000       0.636       1.037\n",
      "x8            -0.0004      0.000     -0.975      0.332      -0.001       0.000\n",
      "==============================================================================\n",
      "Omnibus:                       41.953   Durbin-Watson:                   2.403\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              464.361\n",
      "Skew:                           0.776   Prob(JB):                    1.46e-101\n",
      "Kurtosis:                      12.899   Cond. No.                     1.61e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.61e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Errors from CV are:  [734.51850223924521, 67.458427262209071, 1.0377235647817953, 1.0857527985785336, 2.3979051938372975, 1.0739505760943466, 0.01416111388145796, 0.22218300144855707, 0.18820983469492433, 0.089324979430604315]\n",
      "Averaged error is:  80.8086140564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jonny/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1334: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "df_aggregated = None\n",
    "\n",
    "for hashtag, num_tweets in hashtag_dict.items():\n",
    "    print(\"---\")\n",
    "    print(\"Hashtag: \", hashtag)\n",
    "    print(\"---\")\n",
    "    with open(os.path.join('tweet_data','tweets_#' + hashtag +'.txt'), 'r') as file:\n",
    "        df = pd.DataFrame(index=range(num_tweets),\n",
    "                         columns=['date', 'total_tweets', 'total_retweets', 'sum_followers',\n",
    "                                 'max_followers', 'total_replies', 'total_ranking',\n",
    "                                 'total_impressions'])\n",
    "        \n",
    "#total_tweets, total_retweets, sum_followers, \n",
    "#max_followers, time_of_day, toatl_replies, total_ranking, total_impressions\n",
    "        for i, l in enumerate(file):\n",
    "            tweet = json.loads(l)\n",
    "\n",
    "            #get the date for sorting\n",
    "            date = datetime.datetime.fromtimestamp(tweet['firstpost_date'])\n",
    "            df.set_value(i, 'date', date)\n",
    "            df.set_value(i, 'total_tweets', 1)\n",
    "            df.set_value(i, 'total_retweets', tweet['metrics']['citations']['total'])\n",
    "\n",
    "            #will sum and take max in post processing\n",
    "            df.set_value(i, 'sum_followers', tweet['author']['followers'])\n",
    "            df.set_value(i, 'max_followers', tweet['author']['followers'])\n",
    "            df.set_value(i, 'total_replies', tweet['metrics']['citations']['replies'])\n",
    "            df.set_value(i, 'total_ranking', tweet['metrics']['ranking_score'])\n",
    "            df.set_value(i, 'total_impressions', tweet['metrics']['impressions'])\n",
    "\n",
    "        filter_and_test(df)\n",
    "        if df_aggregated is None: #first iteration \n",
    "            df_aggregated = df\n",
    "        else: #aggregate\n",
    "            df_aggregated = pd.concat([df_aggregated, df])\n",
    "\n",
    "            \n",
    "#            full_errors = cv(X_full, y_full, n_splits=10)\n",
    " #           print(\"Errors from full set CV: \", full_errors)\n",
    "  #          print(\"Mean error from CV: \", np.mean(full_errors))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated Data of all Hashtags\n",
    "\n",
    "In the previous step, data of all hashtags was aggregated. The function call below only means something when more than one hashtag is involved, otherwise results will be the same as the previous time interval split, since the dataframe will only contain data from one set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Feb. 1, 8:00 a.m.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.630\n",
      "Model:                            OLS   Adj. R-squared:                  0.624\n",
      "Method:                 Least Squares   F-statistic:                     103.2\n",
      "Date:                Fri, 09 Mar 2018   Prob (F-statistic):           1.31e-99\n",
      "Time:                        15:58:47   Log-Likelihood:                -2538.7\n",
      "No. Observations:                 493   AIC:                             5093.\n",
      "Df Residuals:                     485   BIC:                             5127.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             6.4784      2.466      2.627      0.009       1.633      11.323\n",
      "x2             0.0137      0.150      0.091      0.927      -0.281       0.308\n",
      "x3            -0.0019      0.000     -5.726      0.000      -0.003      -0.001\n",
      "x4             0.0019      0.000      8.030      0.000       0.001       0.002\n",
      "x5            -0.2524      0.164     -1.541      0.124      -0.574       0.069\n",
      "x6             1.4787      1.884      0.785      0.433      -2.224       5.181\n",
      "x7            -0.8167      0.499     -1.637      0.102      -1.797       0.163\n",
      "x8         -2.658e-05      0.000     -0.226      0.821      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                      759.385   Durbin-Watson:                   1.972\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           370641.523\n",
      "Skew:                           8.218   Prob(JB):                         0.00\n",
      "Kurtosis:                     136.316   Cond. No.                     4.03e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.03e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Errors from CV are:  [10.694077661294902, 11.163409861398719, 14.829019885209823, 10252.185794896926, 11910.651520773967, 37.296861914597855, 1241.0893042809769, 336.42794536395826, 68.731526617074564, 153.3974182715902]\n",
      "Averaged error is:  2403.64668795\n",
      "Between Feb. 1, 8:00 a.m. and 8:00 p.m.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.750\n",
      "Method:                 Least Squares   F-statistic:                     4.753\n",
      "Date:                Fri, 09 Mar 2018   Prob (F-statistic):              0.185\n",
      "Time:                        15:58:47   Log-Likelihood:                -75.367\n",
      "No. Observations:                  10   AIC:                             166.7\n",
      "Df Residuals:                       2   BIC:                             169.2\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           297.7770    158.016      1.884      0.200    -382.110     977.664\n",
      "x2            -9.1687      5.893     -1.556      0.260     -34.525      16.187\n",
      "x3             0.0800      0.065      1.235      0.342      -0.199       0.359\n",
      "x4            -0.0121      0.007     -1.675      0.236      -0.043       0.019\n",
      "x5           -29.5580    114.470     -0.258      0.820    -522.084     462.968\n",
      "x6           855.4949    597.483      1.432      0.289   -1715.267    3426.257\n",
      "x7           -61.6203     32.723     -1.883      0.200    -202.415      79.174\n",
      "x8            -0.0755      0.063     -1.196      0.354      -0.347       0.196\n",
      "==============================================================================\n",
      "Omnibus:                        2.972   Durbin-Watson:                   2.455\n",
      "Prob(Omnibus):                  0.226   Jarque-Bera (JB):                1.544\n",
      "Skew:                          -0.950   Prob(JB):                        0.462\n",
      "Kurtosis:                       2.690   Cond. No.                     5.97e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.97e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Errors from CV are:  [20664677.012114398, 39603901.581337817, 21676923.910048008, 523705.3840576692, 3038297.6346606454, 9694198.660976721, 756213567693.12854, 55046493.142003737, 67727673.706404507, 726730671.66225386]\n",
      "Averaged error is:  75715827423.6\n",
      "After Feb. 1, 8:00 p.m.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.960\n",
      "Model:                            OLS   Adj. R-squared:                  0.957\n",
      "Method:                 Least Squares   F-statistic:                     308.6\n",
      "Date:                Fri, 09 Mar 2018   Prob (F-statistic):           2.44e-68\n",
      "Time:                        15:58:47   Log-Likelihood:                -276.94\n",
      "No. Observations:                 111   AIC:                             569.9\n",
      "Df Residuals:                     103   BIC:                             591.5\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -2.1226      0.519     -4.094      0.000      -3.151      -1.094\n",
      "x2            -0.0761      0.145     -0.525      0.601      -0.364       0.212\n",
      "x3            -0.0012      0.000     -2.780      0.006      -0.002      -0.000\n",
      "x4             0.0016      0.000      9.019      0.000       0.001       0.002\n",
      "x5             0.0144      0.024      0.604      0.547      -0.033       0.062\n",
      "x6            -4.7004      1.490     -3.154      0.002      -7.656      -1.745\n",
      "x7             0.8364      0.101      8.270      0.000       0.636       1.037\n",
      "x8            -0.0004      0.000     -0.975      0.332      -0.001       0.000\n",
      "==============================================================================\n",
      "Omnibus:                       41.953   Durbin-Watson:                   2.403\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              464.361\n",
      "Skew:                           0.776   Prob(JB):                    1.46e-101\n",
      "Kurtosis:                      12.899   Cond. No.                     1.61e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.61e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Errors from CV are:  [734.51850223924521, 67.458427262209071, 1.0377235647817953, 1.0857527985785336, 2.3979051938372975, 1.0739505760943466, 0.01416111388145796, 0.22218300144855707, 0.18820983469492433, 0.089324979430604315]\n",
      "Averaged error is:  80.8086140564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jonny/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1334: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    }
   ],
   "source": [
    "filter_and_test(df_aggregated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fan Base Predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"put title here for your project's scope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
